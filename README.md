
---

# ğŸ§  AI-Powered CV to Job Matcher

This project is an AI-based web scraping and job matching tool that leverages OCR, NLP, and LLMs to read a user's CV and suggest job opportunities that align with the candidateâ€™s skills and experience.

---

## ğŸš€ Features

- ğŸ“ **CV Parsing**: Converts PDF CVs into structured text using OCR and text block analysis.
- ğŸ§  **Semantic Matching**: Embeds CV content into a vector space for similarity-based job relevance matching using Weaviate.
- ğŸŒ **Web Scraping**: Scrapes job listings using `crawl4ai` and extracts structured data using LLM-based extraction.
- ğŸ“„ **Output**: Saves top matched jobs in a CSV for easy viewing and integration.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ ocr.py                # Converts PDF to structured text
â”œâ”€â”€ main.py               # Embeds CV into Weaviate, runs scraper and LLM matching
â”œâ”€â”€  venue.py             # Contains scraping and job extraction logic
â”œâ”€â”€ models/
â”‚   â””â”€â”€ venue.py          # Job schema model
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_utils.py     # Helpers for saving data and filtering
â”‚   â””â”€â”€ scraper_utils.py  # Scraper-related utilities
â”œâ”€â”€ extracted_texts/      # Output folder for OCR-processed text
â”œâ”€â”€ extracted_images/     # Extracted images from the CV (if any)
â”œâ”€â”€ complete_venues.csv   # Final matched job listings
```

---

## âš™ï¸ Technologies Used & Why

### ğŸ”¹ Python
Used for overall backend scripting due to its rich ecosystem in AI, OCR, and web scraping.

### ğŸ”¹ PyMuPDF (`fitz`)
Used to extract both text and images from the uploaded PDF CV. It provides precise control over layout blocks, fonts, and text formatting.

### ğŸ”¹ Tesseract OCR (`pytesseract`)
Used to convert any images (scanned signatures, certificates, etc.) inside the CV to text. Helps enhance the completeness of the CV content before analysis.

### ğŸ”¹ LangChain
Used to split the CV into logical chunks and interface with vector databases like Weaviate. It simplifies working with large documents and embeddings.

### ğŸ”¹ HuggingFace Transformers
Provides high-quality language embeddings that represent the semantic meaning of the CV content. These are then stored in Weaviate.

### ğŸ”¹ Weaviate (Vector Database)
Used to store the semantic vector representation of the CV chunks and perform similarity search against job prompts. Weaviate is fast, scalable, and integrates smoothly with LangChain.

### ğŸ”¹ crawl4ai
An intelligent web scraping framework powered by LLMs. It allows automatic extraction of structured data from HTML pages using prompt-driven extraction logic.

### ğŸ”¹ AsyncIO
Used to perform concurrent scraping across multiple pages without blocking, improving speed and performance.

### ğŸ”¹ LLM Extraction Strategy (`groq/deepseek`)
Used to extract only the most relevant jobs based on the userâ€™s CV context. It ensures meaningful matches instead of random job listings.

---

## ğŸ§ª How It Works

1. **Step 1 â€“ Add your CV**  
   Place your `cv.pdf` inside the root directory of the project.

2. **Step 2 â€“ Run OCR**  
   Execute the following to extract all text and images from the PDF:
   ```bash
   python ocr.py
   ```

   - ğŸ“‚ Output: `extracted_texts/cv.txt` (structured text of your CV)

3. **Step 3 â€“ Run Job Matching**  
   Run the main logic that matches your CV content to current job listings:
   ```bash
   python main.py
   ```

   This script:
   - Embeds your CV
   - Uploads chunks into Weaviate
   - Scrapes job listings
   - Matches them using LLM extraction logic
   - Saves final job matches in `complete_venues.csv`

---

## ğŸ§© Internal Workflow

```
cv.pdf
  â†“ (ocr.py)
cv.txt
  â†“ (main.py)                     â†“ (scrape.py)
Vectorized Embeddings â†’ Weaviate â† Scraped Jobs â† Dialog.lk
         â†“                                â†“
     LLM-based Matching (LLMExtractionStrategy)
         â†“
     Output CSV: complete_venues.csv
```

---

## âœ… Requirements

- Python 3.8+
- Install dependencies:
  ```bash
  pip install -r requirements.txt
  ```

---

## ğŸ“Œ Notes

- Ensure `Tesseract-OCR` is installed on your machine and its path is correctly set in `ocr.py`.
- Make sure to update your `.env` file with the `GROQ_API_KEY` and any other necessary keys.

---

## ğŸ§  Future Improvements

- Upload CVs via a simple web interface
- Add support for multiple LLM providers (e.g., OpenAI, Anthropic)
- Improve job source diversity (LinkedIn, Glassdoor, etc.)

---

## ğŸ‘¨â€ğŸ’» Author

Made with â¤ï¸ by Gihan Lakmal

